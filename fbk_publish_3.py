#!/usr/bin/env python3.4
#
# fbk_publish_3.py -- Uses the Facebook Graph API to grab and store posts locally. 
#
# 	Created by Timothy Wright <spartas@gmail.com>
#		Version 1.0 [March 4th, 2014]
#		* Has it really been over a year since I last updated? Facebook keeps changing their stylesheets and output
#			formats, which keeps me on my feet. No sooner than I can get a release out, they've gone and changed things
#			up again. Now, they've completely removed the post privacy, which makes the download utterly useless for
#			my purposes with fbk_sanitize.
#
#		Version 1.1 [March 26th, 2014]
#		* I've really been trying to keep the non-standard dependencies short on this one. Alas, I added the 
#			requirement that '''tzlocal''' be installed to support converting between timezones for the local user.
#			This is one of those cases where I can't really justify adding in the requirement, but I feel that it adds 
#			a good bit to the user experience that I'm leaving it in.
#
#		* Commented a few ambitiousities, and cleaned up some of the hard-coded strings that were specific to my use 
#			case.
#
#		Version 1.2 [April 1st, 2014]
#		* Updated transform() to add a UNIX_TIMESTAMP to each post.
#
#		* Stripped out the hacky "merge_where" / "merge_compat_id" brokenness. I've replaced it with proper checking
#			by post timestamp. I'm having to retain a copy of each post in memory in order to filter out by timestamp 
#		
#		* Added in a "Generated by fbk_utils" HTML comment, for those not using the sanitize_publish method
#
#		Version 1.3 [April 1st, 2014]
#		* All posts include the parent facebook_id
# 
# 		Version 1.4 [2016?]
#		* Updated to BS4

import argparse
import os
from bs4 import BeautifulSoup, Tag, Comment
import sqlite3
import sys
import re
import json
from fbk_config import fbk_config
from datetime import datetime
from tzlocal import get_localzone

def write_outfile( contents, outfilepath, filename ):
	outfile = open(os.path.join(outfilepath, filename), 'w')
	outfile.write( contents )
	outfile.close()

def transform(o_post):
	ts = datetime.strptime(o_post[2], "%Y-%m-%dT%H:%M:%S%z")

	zts = ts.isoformat()		

	ts = ts.astimezone( local_tz )

	dy = ts.strftime("%e").strip()
	hr = ts.strftime("%l").strip()
	ap = ts.strftime("%p").lower()

	nixts = ts.strftime("%s")
	strts = ts.strftime("%A, %B " + dy + ", %Y at " + hr + ":%M" + ap + " %Z")
	sants = ts.strftime("%B " + dy + ", %Y at " + hr + ":%M " + ap )

	dt = ts.strftime("%Y%m%d")

	msg = o_post[1].replace('\n', '<br />\n')


	return {
		'fbk_id' 		: o_post[0],
		'message' 		: msg,
		'created_timestamp'	: zts,
		'privacy_description'	: o_post[2],
		'formatted_timestamp'	: strts,
		'sanitized_timestamp'	: sants,
		'unix_timestamp'	: int(nixts),
		'date'			: dt,
	}

# This is called sanitize_publish for a reason. It will _ONLY_ operate properly on old-style Facebook export data
# formats, which were supported by fbk_sanitize. I hope that this method will go away completely in the future.
def sanitize_publish(fname):

	cxn = sqlite3.connect( os.path.join(config_dir, 'fbk_cache.db') )
	cur = cxn.cursor()

	f = open(fname, 'r')
	soup = BeautifulSoup( f.read(), "html.parser" )
	f.close()

	if obj_config['graph']['merge_compat_id']:
		cur.execute("SELECT `created_timestamp` FROM `posts` WHERE `id`=?", (obj_config['graph']['merge_compat_id'],))
		source_merge_timestamp = int(datetime.strptime(cur.fetchone()[0], "%Y-%m-%dT%H:%M:%S%z").strftime('%s'))


	sql_fetch_query = """SELECT `fbk_id`,`message`,`created_timestamp`,`privacy_description` FROM `posts` WHERE `privacy_description`='Public' AND `type`='status' 
	ORDER BY `created_timestamp` DESC"""
	
	cur.execute(sql_fetch_query)

	posts = []
	for post in cur.fetchall():
		p = transform(post)

		if not source_merge_timestamp or p['unix_timestamp'] > source_merge_timestamp:
			posts.append( transform(post) )

	str_posts = ''
	for p in posts:
		str_posts = str_posts +  """<div class="feedentry hentry" id="fb_%s">
		         <span class="author vcard">
		          <span class="profile fn">
		           %s
		          </span>
		         </span>
		         <span class="entry-title entry-content">
		          %s
		         </span>
		         <div class="timerow">
		          <time class="time published" datetime="%s" data-date="%s">
		           %s
		          </time>
		         </div>
		        </div>""" % (p['fbk_id'], obj_config['name'], p['message'], p['date'], p['created_timestamp'], p['sanitized_timestamp'])


	cxn.close()


	content_tag = soup.find(id='content') 
	if not content_tag:
		print("No suitable content ID found in the source document. Exiting.")
		sys.exit(7)

	posts = BeautifulSoup("<div>" + str_posts + "</div>", "html.parser").find('div').contents + content_tag.contents
	#posts = content_tag.contents
	#posts = BeautifulSoup("<div id='contents'>" + str_posts + "</div>").find('div').contents

	content_tag.contents = posts

	str_outfile_dt = datetime.now().strftime('%Y-%m-%d_%H_%M_%S')
	dest_path = "wall-%s.html" % str_outfile_dt
	write_outfile(soup.prettify(), '', dest_path)


def publish(fname, full=True):
	cxn = sqlite3.connect( os.path.join(config_dir, 'fbk_cache.db') )
	cur = cxn.cursor()
	local_tz = get_localzone() 


	sql_fetch_query = """SELECT `fbk_id`,`message`,`created_timestamp`,`privacy_description` FROM `posts` WHERE `privacy_description`='Public' AND `type`='status' 
	ORDER BY `created_timestamp` DESC"""
	cur.execute(sql_fetch_query)


	soup = BeautifulSoup( """<html><head><title>%s â€” Wall</title>
			<meta charset="utf-8">
			<link rel="stylesheet" href="style.css" type="text/css">
			</head>
			<body><table id="main"><thead /><tfoot /><tbody /></table></body></html>""" % obj_config['name'], "html.parser")

	body = soup.find('body')

	h1 = soup.new_tag('h1')
	h1.string = obj_config['name']

	if obj_config['tagline']:
		

		span = soup.new_tag('span')
		span['id'] = "tagline"
		span.string = obj_config['tagline']

		h1.append(span)


	body.append(h1)

	main_body = BeautifulSoup( '<div id="content" />', "html.parser" )
	main = main_body.find(id='content')


	for post in cur.fetchall():

		p = transform(post)

		soup_post = BeautifulSoup("""<div class="feedentry hentry" id="fb_%s">
			<span class="author vcard"><span class="fn profile">%s</span></span>
			<span class="entry-title entry-content">%s</span>
	        <div class="timerow">
	        <time class="time published" title="%s" data-date="%s">
	        %s
	        </time>
	        </div>
			</div>""" % (p['fbk_id'], obj_config['name'], p['message'], p['created_timestamp'], p['date'], p['sanitized_timestamp']), "html.parser" )


		main.append(soup_post)

	now = datetime.now(local_tz)
	fbk_util_comment = soup.new_string("Generated by fbk_utils %s" % now.isoformat(), Comment)
	main.append(fbk_util_comment)

	if full:
		body.append(main_body)
		write_outfile( soup.prettify(), '.', 'wall-full.html' )
	else:
		write_outfile( main_body.prettify(), '.', 'wall-posts.html' )

	cxn.close()

	return

# Main()
if __name__ == "__main__":
	global local_tz

	# Process arguments
	parser = argparse.ArgumentParser(description='Publish content from _fetch to html pages')

	parser.add_argument('-f', '--config-file', metavar='CONFIG_FILE', 
			help='A JSON-structured file containing configuration directives to use for the script')

	parser.add_argument('-s', '--sanitize-publish', metavar='SANITIZE_PUBLISH',
			help="""Use the sanitize publish feature (an older HTML format) instead. 
			Specify the old wall.html with this feature""")

	parser.add_argument('-P', '--posts-only', action="store_true",
			help="""Output only the structured content of posts, in a minimal HTML document.""")

	parser.add_argument('--version', action='version', version='%(prog)s 1.2')

	args = parser.parse_args()


	config_dir = ".fbk"
	use_configdir = os.path.exists( config_dir )

	if use_configdir == False:
		config_dir = os.path.join( os.path.expanduser('~'), '.fbk' )
		use_configdir = os.path.exists( config_dir )

	# Default obj_config
	
	file_configfile = None
	if(args.config_file):
		file_configfile = os.path.abspath(args.config_file)
	elif( use_configdir and os.path.exists(os.path.join(config_dir, 'config.json'))):
		file_configfile = os.path.join(config_dir, 'config.json')

	if(file_configfile):
		obj_config = fbk_config.parse_config( file_configfile )

	if( args.sanitize_publish and not(os.path.exists(args.sanitize_publish)) ):
		print("File (%s) does not exist" % args.sanitize_publish)
		sys.exit(3)

	local_tz = get_localzone()


	if(args.sanitize_publish):
		sanitize_publish(args.sanitize_publish)
	else:
		publish(args.sanitize_publish, not args.posts_only)

	sys.exit(0)
